{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data collection activities\n",
    "All the data collection activities are automated using user defined functions retrievable in the folder `scripts`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cef29dc85632b19"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-11T07:55:32.414771414Z",
     "start_time": "2023-10-11T07:55:32.361989730Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as requests\n",
    "from scripts import user, item, discussion, link\n",
    "import csv\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Item scraping\n",
    "The following code saves items data into a csv file, provided a range of item codes fixed by the operator.\n",
    "\n",
    "First of all we need to initialize all the files for data collection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b87be68b26ebf12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization of csv files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c03ba9743017eaa9"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Discussion items\n",
    "file_path_discussion = \"../data/discussion.csv\"\n",
    "row_head_discussion = [\"Title\",\n",
    "            \"Item code\",\n",
    "            \"Banner data\",\n",
    "            \"Main link\",\n",
    "            \"Body links\"\n",
    "            \"Sats received by comments\",\n",
    "            \"Comments item code\",\n",
    "            ]\n",
    "    \n",
    "with open(file_path_discussion, 'w', encoding='utf_8_sig', newline=\"\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(row_head_discussion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T07:55:33.963443360Z",
     "start_time": "2023-10-11T07:55:33.953569577Z"
    }
   },
   "id": "6564de73a2be1f53"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Link items\n",
    "file_path_link = \"../data/link.csv\"\n",
    "row_head_link = [\"Title\",\n",
    "                 \"Item code\",\n",
    "                 \"Banner data\",\n",
    "                 \"Main link\",\n",
    "                 \"Body links\",\n",
    "                 \"Sats received by comments\",\n",
    "                 \"Comments item code\",\n",
    "                 ]\n",
    "\n",
    "with open(file_path_link, 'w', encoding='utf_8_sig', newline=\"\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(row_head_link)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T07:55:34.784991225Z",
     "start_time": "2023-10-11T07:55:34.761287987Z"
    }
   },
   "id": "889c75a273fc413b"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Try to scrape 150 different items rather than in 'progressive item mode'\n",
    "from random import sample\n",
    "\n",
    "sampled_items = sample([*range(1,200000)], 150)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T07:55:35.934952131Z",
     "start_time": "2023-10-11T07:55:35.922774239Z"
    }
   },
   "id": "e819de3d57c3aa0a"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117051, 172917, 23628, 122322, 148790, 118583, 126295, 170115, 44573, 79661, 61754, 198407, 38996, 42937, 22607, 101291, 53826, 181380, 23293, 139928, 106326, 3493, 159436, 151087, 128425, 89287, 78252, 37951, 10085, 111728, 132099, 104125, 134642, 136172, 42156, 80426, 160539, 58713, 54915, 67151, 104360, 111163, 129251, 100956, 123294, 185415, 151718, 169572, 184756, 31511, 157624, 18738, 44112, 83132, 149515, 16285, 146816, 153359, 157612, 49047, 132319, 61280, 34743, 146305, 89583, 127563, 97234, 54849, 63692, 139817, 2250, 161890, 151022, 91955, 64231, 151172, 97236, 164425, 170670, 184669, 189817, 91620, 174945, 30635, 167266, 166996, 135345, 15968, 75857, 62972, 32651, 297, 55264, 47321, 171565, 5680, 168979, 61816, 51375, 99554, 5406, 92492, 109507, 49725, 180073, 197577, 117829, 184161, 58322, 96259, 47234, 170970, 154075, 55812, 150012, 141341, 127630, 165882, 43734, 48442, 115406, 45174, 70018, 121171, 122501, 7186, 38308, 183350, 168510, 171573, 114810, 143559, 172233, 183735, 128408, 107771, 136506, 168313, 48098, 164186, 94330, 117433, 178596, 93493, 25823, 16932, 9094, 62711, 27135, 32733]\n"
     ]
    }
   ],
   "source": [
    "print(sampled_items)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T07:55:37.085565970Z",
     "start_time": "2023-10-11T07:55:37.064233145Z"
    }
   },
   "id": "5622bfb2d27b3ab8"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [03:10<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(sampled_items):\n",
    "    try:\n",
    "        # Provided a string returns a bs4.BeautifulSoup object\n",
    "        url_posts = f'https://stacker.news/items/{i}'\n",
    "        response = requests.get(url_posts)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        if item.detect_item_type(i, soup)=='discussion':\n",
    "            entry = [discussion.extract_title(soup),\n",
    "                     str(i),\n",
    "                     discussion.extract_banner(soup),\n",
    "                     discussion.extract_body_links(soup),\n",
    "                     discussion.extract_comment_stacked(soup),\n",
    "                     discussion.extract_comment_item_code(soup)\n",
    "                     ]\n",
    "            \n",
    "            # Appends every new profile to a csv file in the provided path\n",
    "            try:\n",
    "                with open(file_path_discussion, 'a', encoding='utf_8_sig', newline=\"\") as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                    csvwriter.writerow(entry)\n",
    "            except:\n",
    "                print('Error while processing data')\n",
    "        \n",
    "        if item.detect_item_type(i, soup)=='link':\n",
    "            entry = [link.extract_title(soup),\n",
    "                     str(i),\n",
    "                     link.extract_banner(soup),\n",
    "                     link.extract_link(soup),\n",
    "                     link.extract_body_links(soup),\n",
    "                     link.extract_comment_stacked(soup),\n",
    "                     link.extract_comment_item_code(soup)\n",
    "                     ]\n",
    "            # Appends every new profile to a csv file in the provided path\n",
    "            try:\n",
    "                with open(file_path_link, 'a', encoding='utf_8_sig', newline=\"\") as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                    csvwriter.writerow(entry)\n",
    "            except:\n",
    "                print('Error while processing data')\n",
    "        \n",
    "    except:\n",
    "        continue\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T07:58:49.561466820Z",
     "start_time": "2023-10-11T07:55:38.602726118Z"
    }
   },
   "id": "4f0d197720b15859"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
