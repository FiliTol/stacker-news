{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-05T08:32:28.889139469Z",
     "start_time": "2023-10-05T08:32:28.847422021Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as requests\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from user_modules import scraping_user as su\n",
    "from user_modules import scraping_item as si"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test chunck"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c0978c01a736aa8"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of above program is : 4.7752416133880615 s\n",
      "['El Salvador Makes Bitcoin Legal Tender', 'stacker news soft launch AMA']\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(1,5):\n",
    "    \n",
    "    try:\n",
    "        url_posts = 'https://stacker.news/items/%d' % (i)\n",
    "        response = requests.get(url_posts)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        title = soup.find_all('a', class_='item_title__FH7AS text-reset me-2')\n",
    "        \n",
    "        for e in title:\n",
    "            titles.append(e.get_text())\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start), \"s\")\n",
    "print(titles)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T06:39:29.394344230Z",
     "start_time": "2023-10-05T06:39:24.603784193Z"
    }
   },
   "id": "c1b53dd5238f1a54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect post header with all the related data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22c54d832a42cfb6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "url_posts = 'https://stacker.news/items/1'\n",
    "response = requests.get(url_posts)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "titolo = soup.find('a', class_='item_title__FH7AS text-reset me-2').get_text()\n",
    "banner = soup.find('div', class_='item_other__MjgP3')\n",
    "\n",
    "#post_stack = banner.find('span').text\n",
    "\n",
    "banner_data = []\n",
    "\n",
    "for i in banner.find_all('span'):\n",
    "    banner_data.append(i.text)\n",
    "    \n",
    "#n_comments = soup.find('a', class_='text-reset position-relative').get_text()\n",
    "#nym_creator = banner.find('a', ) \n",
    "\n",
    "print([titolo, banner_data])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83f77a4a0af8c262"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scraping Items of stacker.news"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0413ab8459c1374"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## ALBERTO\n",
    "df = pd.DataFrame(columns=['titolo', 'numero commenti', 'boost', 'sats', 'betha',\"commentors\"])\n",
    "n_posts = range(1,20)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for number in n_posts:\n",
    "    # print(\"Doing\", number)\n",
    "    url_posts = f'https://stacker.news/items/{number}'\n",
    "    response = requests.get(url_posts)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        contenuto=soup.find('div', class_=\"item_fullItemContainer__ZAYtZ\").get_text()\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        titolo = soup.find('a', class_='item_title__FH7AS text-reset me-2').get_text()\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        banner = soup.find('div', class_='item_other__MjgP3')\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        commento = soup.find('a', class_='text-reset position-relative').get_text()\n",
    "    except:        \n",
    "        continue\n",
    "    try:\n",
    "        a_elements = soup.find_all('a')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    at_elements = []\n",
    "\n",
    "    for el in a_elements:\n",
    "        links = el.get_text()\n",
    "    \n",
    "        if links.startswith('@'):\n",
    "            at_elements.append(el)\n",
    "    \n",
    "    commentors_list=[]\n",
    "    for ind in range(0,len(at_elements)):\n",
    "        commentors_list.append(at_elements[ind][\"href\"])\n",
    "\n",
    "\n",
    "    banner_data = []\n",
    "    for i in banner.find_all('span'):\n",
    "        banner_data.append(i.text)\n",
    "    index=number-1\n",
    "    for b in banner_data:\n",
    "        if \"boost\" in b:\n",
    "            df.at[index, 'boost'] = b\n",
    "        if \"sats\" in b:\n",
    "            df.at[index, 'sats'] = b\n",
    "        if \"@\" in b:\n",
    "            df.at[index, 'betha'] = b   # TODO: insert the datetime extraction function\n",
    "\n",
    "    df.at[index, 'titolo'] = titolo\n",
    "    df.at[index, 'numero commenti'] = commento\n",
    "    df.at[index, 'contenuto'] = contenuto\n",
    "    df.at[index, 'commentors'] = commentors_list\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start), \"s\")\n",
    "\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd47a5648c207ac9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reframing the previous code\n",
    "Main steps in the code\n",
    "1. Retrieve item webpage provided the item code\n",
    "2. Detect item type:\n",
    "    - Comment or post ?\n",
    "    - If post, which kind of post:\n",
    "        1. Discussion\n",
    "        2. Link\n",
    "        3. Poll\n",
    "        4. Bounty\n",
    "        5. Job\n",
    "3. Retrieve title\n",
    "4. Retrieve banner\n",
    "    - Extract number of comment, **compulsory**\n",
    "    - Extract stacked amount by the item, **if present**\n",
    "    - Extract Boost value, **if present**\n",
    "    - Extract username, **compulsory**\n",
    "    - Extract timestamp, **compulsory**\n",
    "    - Extract badge, **compulsory**\n",
    "5. Extract amount stacked by comments, **compulsory**\n",
    "6. Extract item code of comments **OR** extract user that commented\n",
    "\n",
    "**Note that**:\n",
    "- Some items do not have the stacked amount nor the possibility to receive sats. For example the user @saloon created all this kind of posts. Is he/she a bot? Is it an 'official bot' of the forum and so it's not possible to give sats to it?\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cd9ceda58f8bbc2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detecting item types\n",
    "First of all we need to determine the kind of item we are working with.\n",
    "The typology is described by the tag of the post in the post-creation, \n",
    "\n",
    "#### Job\n",
    "Job offers items are identifiable by the **APPLY** button.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7397c7e162d9e3d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def detect_item_job():\n",
    "    pass\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T08:24:59.388801728Z",
     "start_time": "2023-10-05T08:24:59.372040435Z"
    }
   },
   "id": "d0864f7fbcca9cdf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scraping user profiles\n",
    "Users profiles are scraped starting from the list of users extracted by scraping all the items (posts+comments)\n",
    "The link to get the user profile is `https://stacker.news/$username$` "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7771202dfaced9e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modularize the code - user profile scraping\n",
    "Define functions to modularize and simplify the user profile scraping.\n",
    "The functions are defined in `user_modules/scraping_user.py` and have been tested with `tests/test_scraping_user.py`. To run the tests open a the terminal/CMD and run the script `tests/test_scraping_user.py` from there, running it from a JupyterNotebook could raise errors.\n",
    "The testing script tested every function in some corner cases (missing data/request error). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e52500e0ab6223e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**From the following two approaches we can create the final script for scraping the user profiles**.\n",
    "The next step would be the creation of a function that loops through the user list and assigns to the rows in the dataframe the values returned from the functions defined in `user_modules/scraping_user.py`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efe3fde8a3810bc4"
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123353\n",
      "53789\n",
      "357270\n",
      "181422\n",
      "1114441\n",
      "6427\n",
      "0\n",
      "50703\n",
      "164002\n",
      "1369008\n",
      "The average time of execution of the above program for one user is : 0.6400596380233765 s\n"
     ]
    }
   ],
   "source": [
    "# TODO: integrate this method into the general scraping script for profile scraping\n",
    "\n",
    "user_list = np.array(['Monotone',\n",
    "                      'TNStacker',\n",
    "                      'kale',\n",
    "                      'DiracDelta',\n",
    "                      'kr',\n",
    "                      'moscowTimeBot',\n",
    "                      'mpuels',\n",
    "                      'blockstream_official',\n",
    "                      'nym',\n",
    "                      'random_'\n",
    "                      ])\n",
    "                      \n",
    "start = time.time()\n",
    "\n",
    "for i in np.nditer(user_list):\n",
    "    print(su.get_total_stacked(i))\n",
    "    \n",
    "end = time.time()\n",
    "print(\"The average time of execution of the above program for one user is :\",\n",
    "      (end-start)/len(user_list), \"s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:44:21.423256306Z",
     "start_time": "2023-10-04T22:44:15.021083037Z"
    }
   },
   "id": "19462e10c12c6aed"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123353\n",
      "53789\n",
      "357270\n",
      "181422\n",
      "1114441\n",
      "6427\n",
      "0\n",
      "50703\n",
      "164002\n",
      "1369008\n",
      "The average time of execution of the above program for one user is : 0.691546106338501 s\n"
     ]
    }
   ],
   "source": [
    "user_list = ['Monotone',\n",
    "             'TNStacker',\n",
    "             'kale',\n",
    "             'DiracDelta',\n",
    "             'kr',\n",
    "             'moscowTimeBot',\n",
    "             'mpuels',\n",
    "             'blockstream_official',\n",
    "             'nym',\n",
    "             'random_',\n",
    "             ]\n",
    "                      \n",
    "start = time.time()\n",
    "\n",
    "for i in user_list:\n",
    "    print(su.get_total_stacked(i))\n",
    "    \n",
    "end = time.time()\n",
    "print(\"The average time of execution of the above program for one user is :\",\n",
    "      (end-start)/len(user_list), \"s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:45:42.499201556Z",
     "start_time": "2023-10-04T22:45:35.576494260Z"
    }
   },
   "id": "930f937ca7b5188f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
