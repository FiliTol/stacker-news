{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-04T17:15:23.144629925Z",
     "start_time": "2023-10-04T17:15:22.931560857Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as requests\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "## Key variables valid for all the chuncks\n",
    "timestamp_pattern = re.compile(r'(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z)')\n",
    "original_format = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "desired_format = \"%Y-%m-%d %H:%M:%S\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T17:15:25.742446521Z",
     "start_time": "2023-10-04T17:15:25.734514740Z"
    }
   },
   "id": "43c8560280689a13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test chunck\n",
    "NB: need to solve the problem of some items not having a title (these are the comments). At the current time, I solved the problem with a `try - except`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c0978c01a736aa8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    try:\n",
    "        url_posts = 'https://stacker.news/items/%d' % (i)\n",
    "        response = requests.get(url_posts)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        title = soup.find_all('a', class_='item_title__FH7AS text-reset me-2')\n",
    "        \n",
    "        for e in title:\n",
    "            titles.append(e.get_text())\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start), \"s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T07:55:47.488266126Z",
     "start_time": "2023-10-04T07:55:40.108224898Z"
    }
   },
   "id": "c1b53dd5238f1a54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect post header with all the related data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22c54d832a42cfb6"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['El Salvador Makes Bitcoin Legal Tender', ['603 sats', ' \\\\ ', '4 boost', ' \\\\ ', ' \\\\ ', '@k00b  11 Jun 2021', ' ', '', ' ', 'bitcoin', '']]\n"
     ]
    }
   ],
   "source": [
    "url_posts = 'https://stacker.news/items/1'\n",
    "response = requests.get(url_posts)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "titolo = soup.find('a', class_='item_title__FH7AS text-reset me-2').get_text()\n",
    "banner = soup.find('div', class_='item_other__MjgP3')\n",
    "\n",
    "#post_stack = banner.find('span').text\n",
    "\n",
    "banner_data = []\n",
    "\n",
    "for i in banner.find_all('span'):\n",
    "    banner_data.append(i.text)\n",
    "    \n",
    "#n_comments = soup.find('a', class_='text-reset position-relative').get_text()\n",
    "#nym_creator = banner.find('a', ) \n",
    "\n",
    "print([titolo, banner_data])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:45:46.701773660Z",
     "start_time": "2023-10-04T15:45:45.275482782Z"
    }
   },
   "id": "83f77a4a0af8c262"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect timestamp of post creation\n",
    "The following code scans the parsed html response looking for an `<a>` tag that has an attribute `title` matching the timestamp format in the website.\n",
    "Then it extracts it and turns it into a datetime object. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ed3193d82a84bf8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-11 19:26:02.662000\n"
     ]
    }
   ],
   "source": [
    "url_posts = 'https://stacker.news/items/1'\n",
    "response = requests.get(url_posts)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "timestamp_element = soup.find('a', attrs={'title': timestamp_pattern})\n",
    "timestamp_match = timestamp_pattern.search(timestamp_element['title']).group(1)\n",
    "\n",
    "timestamp_datetime = datetime.strptime(timestamp_match, original_format)\n",
    "\n",
    "print(timestamp_datetime)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T16:41:01.133921699Z",
     "start_time": "2023-10-04T16:41:00.085128832Z"
    }
   },
   "id": "a4979c26e0683acb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scraping user profiles\n",
    "Users profiles are scraped starting from the list of users extracted by scraping all the items (posts+comments)\n",
    "The link to get the user profile is `https://stacker.news/$username$` "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7771202dfaced9e6"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking since: #1\n"
     ]
    }
   ],
   "source": [
    "## Test user - the creator of stacker.news\n",
    "\n",
    "url_posts = 'https://stacker.news/k00b'\n",
    "response = requests.get(url_posts)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Nym \n",
    "nym = soup.find('div', class_='user-header_username__bqOV1').get_text()\n",
    "\n",
    "# This could became a function\n",
    "nym_tot_stacked = soup.find('div', class_='mb-2 ms-0 ms-sm-1 user-header_username__bqOV1 text-success').get_text()\n",
    "regex_sats = r'[^\\d]+'\n",
    "nym_tot_stacked = re.sub(regex_sats, '', nym_tot_stacked)\n",
    "\n",
    "# Nym address\n",
    "nym_lnaddress = soup.find('button', class_='fw-bold ms-0 btn btn-primary', type='button').get_text()\n",
    "\n",
    "# Stacking since -> first user appearance (measured by the first item he/she created)\n",
    "# We need to decide the datatype for this index -> string is better\n",
    "nym_first_item = soup.find('a', class_='ms-1').get_text()[1]\n",
    "\n",
    "# Longest cowboy hat streak (README.md for cowboy-hat meaning)\n",
    "nym_ch_streak = soup.find('small', class_='text-muted d-flex-inline').get_text()\n",
    "#regex_ch = r'[^\\d]+'\n",
    "#nym_ch_streak = re.sub(regex_ch, '', nym_ch_streak)\n",
    "\n",
    "print(nym_ch_streak)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T17:49:03.059091346Z",
     "start_time": "2023-10-04T17:49:01.367724020Z"
    }
   },
   "id": "15d37cfa68a482fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
